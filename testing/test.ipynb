{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-JdttxN47aiGcSQxuhTi5HUySqrIeMEVclraZ2Pv6qyT3BlbkFJpJNWSGNQAik_AV4TRO3cMqzZD5zLjFrBM6M4kHITAA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI()\n\u001b[1;32m----> 6\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite a haiku about ai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\resources\\chat\\completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-JdttxN47aiGcSQxuhTi5HUySqrIeMEVclraZ2Pv6qyT3BlbkFJpJNWSGNQAik_AV4TRO3cMqzZD5zLjFrBM6M4kHITAA\"\n",
    "client = openai.OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
      "     ------------------------------------ 367.8/367.8 kB 603.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.5.0-cp310-none-win_amd64.whl (190 kB)\n",
      "     ------------------------------------ 191.0/191.0 kB 608.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.9.0-py3-none-any.whl (434 kB)\n",
      "     ------------------------------------ 434.3/434.3 kB 617.3 kB/s eta 0:00:00\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.4/78.4 kB 724.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.23.2\n",
      "  Downloading pydantic_core-2.23.2-cp310-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 638.8 kB/s eta 0:00:00\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "     ------------------------------------ 345.4/345.4 kB 612.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: tzdata, tqdm, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.5.0 openai-1.44.0 pydantic-2.9.0 pydantic-core-2.23.2 tqdm-4.66.5 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python SDK\n",
    "import google.generativeai as genai\n",
    "# Used to securely store your API key\n",
    "from google.colab import userdata\n",
    "\n",
    "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key='AIzaSyDJUExlPm4OHqDwBmmA1HqYldUVSwWrZxc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(\"Extra\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Downloading cohere-5.9.1-py3-none-any.whl (221 kB)\n",
      "     ------------------------------------ 221.3/221.3 kB 562.7 kB/s eta 0:00:00\n",
      "Collecting httpx-sse==0.4.0\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from cohere) (2.9.0)\n",
      "Collecting fastavro<2.0.0,>=1.9.4\n",
      "  Downloading fastavro-1.9.7-cp310-cp310-win_amd64.whl (497 kB)\n",
      "     ------------------------------------ 497.2/497.2 kB 537.4 kB/s eta 0:00:00\n",
      "Collecting types-requests<3.0.0,>=2.0.0\n",
      "  Downloading types_requests-2.32.0.20240907-py3-none-any.whl (15 kB)\n",
      "Collecting tokenizers<1,>=0.15\n",
      "  Downloading tokenizers-0.20.0-cp310-none-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 56.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from cohere) (4.12.2)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from cohere) (0.27.2)\n",
      "Collecting parameterized<0.10.0,>=0.9.0\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from cohere) (2.23.2)\n",
      "Collecting boto3<2.0.0,>=1.34.0\n",
      "  Downloading boto3-1.35.14-py3-none-any.whl (139 kB)\n",
      "     ------------------------------------ 139.2/139.2 kB 305.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from cohere) (2.32.3)\n",
      "Collecting botocore<1.36.0,>=1.35.14\n",
      "  Downloading botocore-1.35.14-py3-none-any.whl (12.5 MB)\n",
      "     -------------------------------------- 12.5/12.5 MB 276.7 kB/s eta 0:00:00\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "     -------------------------------------- 82.7/82.7 kB 289.9 kB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.8)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from pydantic>=1.9.2->cohere) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "     ------------------------------------ 417.5/417.5 kB 457.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from botocore<1.36.0,>=1.35.14->boto3<2.0.0,>=1.34.0->cohere) (2.9.0.post0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.0-py3-none-any.whl (16 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "     ------------------------------------ 161.8/161.8 kB 159.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.5)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "     ------------------------------------ 179.3/179.3 kB 180.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.14->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
      "Installing collected packages: types-requests, pyyaml, parameterized, jmespath, httpx-sse, fsspec, filelock, fastavro, huggingface-hub, botocore, tokenizers, s3transfer, boto3, cohere\n",
      "Successfully installed boto3-1.35.14 botocore-1.35.14 cohere-5.9.1 fastavro-1.9.7 filelock-3.16.0 fsspec-2024.9.0 httpx-sse-0.4.0 huggingface-hub-0.24.6 jmespath-1.0.1 parameterized-0.9.0 pyyaml-6.0.2 s3transfer-0.10.2 tokenizers-0.20.0 types-requests-2.32.0.20240907\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"medical_tests\": [\n",
      "        {\n",
      "            \"test_name\": \"Глюкоза\",\n",
      "            \"reference_range\": \"4,39 - 5,93\",\n",
      "            \"units\": \"ммоль/л\",\n",
      "            \"test_results\": \"134\",\n",
      "            \"test_date\": \"15.07.2024\",\n",
      "            \"test_location\": \"null\",\n",
      "            \"test_address\": \"null\"\n",
      "        },\n",
      "        {\n",
      "            \"test_name\": \"Железо\",\n",
      "            \"reference_range\": \"12,5 - 32,2\",\n",
      "            \"units\": \"мкмоль/л\",\n",
      "            \"test_results\": \"156\",\n",
      "            \"test_date\": \"15.07.2024\",\n",
      "            \"test_location\": \"null\",\n",
      "            \"test_address\": \"null\"\n",
      "        },\n",
      "        {\n",
      "            \"test_name\": \"Ферритин\",\n",
      "            \"reference_range\": \"20,0 - 250,0\",\n",
      "            \"units\": \"нг/мл\",\n",
      "            \"test_results\": \"115.0\",\n",
      "            \"test_date\": \"15.07.2024\",\n",
      "            \"test_location\": \"null\",\n",
      "            \"test_address\": \"null\"\n",
      "        }\n",
      "    ],\n",
      "    \"medical_studies\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get Cohere API key from environment variables or replace with your API key\n",
    "COHERE_API_KEY = 'lFfrPXwrmOSAe6ejaA3vEd9kDuqgd3TpmhdQK0Fo'\n",
    "\n",
    "# Initialize Cohere client\n",
    "co = cohere.Client(COHERE_API_KEY)\n",
    "\n",
    "# Define the prompt template for extracting structured data as JSON\n",
    "prompt_template = \"\"\"\n",
    "You are an AI assistant capable of extracting structured information from medical documents. Given a passage, extract specific information and return it only as a JSON object. The JSON should include the following fields depending on the type of document:\n",
    "\n",
    "Medical Tests (анализы):\n",
    "Test Name \n",
    "Reference Range (e.g., norms for the test)\n",
    "Units (e.g., г/дл, %)\n",
    "Test Results (e.g., numerical values or text)\n",
    "Test Date\n",
    "Test Location (e.g., the name of the medical institution)\n",
    "Test Address\n",
    "Medical Studies (исследования):\n",
    "Study Name (e.g., \"Ультразвуковое исследование\")\n",
    "Study Date\n",
    "Study Location (e.g., the name of the medical institution)\n",
    "Device (e.g., the equipment used for the study)\n",
    "Study Protocol\n",
    "Study Conclusion\n",
    "Study Recommendations\n",
    "Study Address\n",
    "If certain information is not present in the text, return those fields as 'null'. The extracted data should be structured and presented as a json file to the user.\n",
    "\n",
    "Now, process the following text: {input_text}\n",
    "\"\"\"\n",
    "\n",
    "def extract_json_from_text(input_text):\n",
    "    # Format the prompt with the input text\n",
    "    prompt = prompt_template.format(input_text=input_text)\n",
    "    \n",
    "    # Generate the completion using Cohere's generate API\n",
    "    response = co.generate(\n",
    "        model='command-nightly',  # Select the appropriate model, you can experiment with other versions\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,  # Adjust token limit based on your input text length\n",
    "        temperature=0.7,  # Adjust temperature for creativity and accuracy\n",
    "        k=0, \n",
    "        stop_sequences=[],\n",
    "        return_likelihoods='NONE'\n",
    "    )\n",
    "\n",
    "    # Extract and return the JSON part from the response\n",
    "    if response.generations and response.generations[0].text:\n",
    "        # Use regex to find the JSON block in the response\n",
    "        json_match = re.search(r'\\{[\\w\\W]*\\}', response.generations[0].text)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "        else:\n",
    "            return {\"error\": \"No valid JSON found in the response\"}\n",
    "    else:\n",
    "        return {\"error\": \"No valid response from the model\"}\n",
    "\n",
    "# Example usage\n",
    "input_text = \"\"\"\n",
    "РЕЗУЛЬТАТЫ ЛАБОРАТОРНЫХ ИССЛЕДОВАНИЙ\n",
    "ФИО пациента:\n",
    "Шахмурадян Михаил Андреевич\n",
    "Вид биоматериала: Венозная кровь\n",
    "Тип пробы:\n",
    "Дата рождения:\n",
    "07.10.1993\n",
    "Плазма крови\n",
    "Дата поступления\n",
    "биоматериала:\n",
    "14.07.2024 14:26\n",
    "Мужской\n",
    "Пол:\n",
    "Дата выполнения\n",
    "исследования:\n",
    "15.07.2024 12:32\n",
    "Исследование выполнено на автоматическом биохимическом анализаторе AU480 (Beckman Coulter, США)\n",
    "№\n",
    "Исследование\n",
    "Результат\n",
    "Ед. изм.\n",
    "Интерпретация\n",
    "БИОХИМИЧЕСКИЕ ИССЛЕДОВАНИЯ КРОВИ\n",
    "134\n",
    "ммоль/л\n",
    "4.76\n",
    "Глюкоза\n",
    "4,39\n",
    "5,93\n",
    "156\n",
    "мкмоль/л\n",
    "23.1\n",
    "Железо\n",
    "12,5\n",
    "32,2\n",
    "160\n",
    "нг/мл\n",
    "115.0\n",
    "Ферритин\n",
    "20,0\n",
    "250,0\n",
    "Результат лабораторного исследования не является диагнозом. Согласно федеральному закону №323-ФЗ от 21.11.2011 (ред. от\n",
    "29.07.2017) «Об основах охраны здоровья граждан в Российской Федерации» диагноз устанавливает лечащий врач, основываясь\n",
    "на всестороннем обследовании пациента: сбор и анализ жалоб, данные анамнеза и осмотра, проведение лабораторных,\n",
    "инструментальных и иных исследований.\n",
    "Выполнил:\n",
    "Биолог КДЛ Елисеева Л. В.\n",
    "1 из 1\n",
    " B = H Ht) Tt. 8-928-111-22-11\n",
    "_] e-mail: official@ avenumed.ru\n",
    "eb NABOPATOPIA WwWw.avenumed.ru\n",
    "\n",
    "000 “CeBepnan 3Be3ga” WHH 6141045157 OFPH 1136181005135 Siny. J1041-01050-61/00327726\"\"\"\n",
    "\n",
    "extracted_data = extract_json_from_text(input_text)\n",
    "print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropicNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading anthropic-0.34.2-py3-none-any.whl (891 kB)\n",
      "     ------------------------------------ 891.9/891.9 kB 620.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (2.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anthropic) (0.20.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.8)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2024.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from tokenizers>=0.13.0->anthropic) (0.24.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.2.2)\n",
      "Installing collected packages: anthropic\n",
      "Successfully installed anthropic-0.34.2\n"
     ]
    }
   ],
   "source": [
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 117\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     62\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124mРЕЗУЛЬТАТЫ ЛАБОРАТОРНЫХ ИССЛЕДОВАНИЙ\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124mФИО пациента:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124m000 “CeBepnan 3Be3ga” WHH 6141045157 OFPH 1136181005135 Siny. J1041-01050-61/00327726\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 117\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_json_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(extracted_data, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m, in \u001b[0;36mextract_json_from_text\u001b[1;34m(input_text)\u001b[0m\n\u001b[0;32m     40\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(input_text\u001b[38;5;241m=\u001b[39minput_text)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Generate the completion using Claude\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the appropriate Claude model (claude-2 in this case)\u001b[39;49;00m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manthropic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHUMAN_PROMPT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manthropic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAI_PROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens_to_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust the token limit as per the input text\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Extract and return the JSON part from the response\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mand\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Use regex to find the JSON block in the response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\anthropic\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\anthropic\\resources\\completions.py:374\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, max_tokens_to_sample, model, prompt, metadata, stop_sequences, stream, temperature, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_given(timeout) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;241m==\u001b[39m DEFAULT_TIMEOUT:\n\u001b[0;32m    373\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m600\u001b[39m\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/complete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens_to_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens_to_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\anthropic\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\anthropic\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\anthropic\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get Anthropic API key from environment variables or replace with your API key\n",
    "ANTHROPIC_API_KEY = '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'\n",
    "\n",
    "# Initialize Claude client\n",
    "client = anthropic.Client(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "# Define the prompt template for extracting structured data as JSON\n",
    "prompt_template = \"\"\"\n",
    "You are an AI assistant capable of extracting structured information from medical documents. Given a passage, extract specific information and return it only as a JSON object. The JSON should include the following fields depending on the type of document:\n",
    "\n",
    "Medical Tests (анализы):\n",
    "Test Name \n",
    "Reference Range (e.g., norms for the test)\n",
    "Units (e.g., г/дл, %)\n",
    "Test Results (e.g., numerical values or text)\n",
    "Test Date\n",
    "Test Location (e.g., the name of the medical institution)\n",
    "Test Address\n",
    "Medical Studies (исследования):\n",
    "Study Name (e.g., \"Ультразвуковое исследование\")\n",
    "Study Date\n",
    "Study Location (e.g., the name of the medical institution)\n",
    "Device (e.g., the equipment used for the study)\n",
    "Study Protocol\n",
    "Study Conclusion\n",
    "Study Recommendations\n",
    "Study Address\n",
    "If certain information is not present in the text, return those fields as 'null'. The extracted data should be structured and presented as a json file to the user.\n",
    "\n",
    "Now, process the following text: {input_text}\n",
    "\"\"\"\n",
    "\n",
    "def extract_json_from_text(input_text):\n",
    "    # Format the prompt with the input text\n",
    "    prompt = prompt_template.format(input_text=input_text)\n",
    "    \n",
    "    # Generate the completion using Claude\n",
    "    response = client.completions.create(\n",
    "        model=\"claude-2\",  # Use the appropriate Claude model (claude-2 in this case)\n",
    "        prompt=anthropic.HUMAN_PROMPT + prompt + anthropic.AI_PROMPT,\n",
    "        max_tokens_to_sample=500,  # Adjust the token limit as per the input text\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Extract and return the JSON part from the response\n",
    "    if response and response['completion']:\n",
    "        # Use regex to find the JSON block in the response\n",
    "        json_match = re.search(r'\\{[\\w\\W]*\\}', response['completion'])\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "        else:\n",
    "            return {\"error\": \"No valid JSON found in the response\"}\n",
    "    else:\n",
    "        return {\"error\": \"No valid response from the model\"}\n",
    "\n",
    "# Example usage\n",
    "input_text = \"\"\"\n",
    "РЕЗУЛЬТАТЫ ЛАБОРАТОРНЫХ ИССЛЕДОВАНИЙ\n",
    "ФИО пациента:\n",
    "Шахмурадян Михаил Андреевич\n",
    "Вид биоматериала: Венозная кровь\n",
    "Тип пробы:\n",
    "Дата рождения:\n",
    "07.10.1993\n",
    "Плазма крови\n",
    "Дата поступления\n",
    "биоматериала:\n",
    "14.07.2024 14:26\n",
    "Мужской\n",
    "Пол:\n",
    "Дата выполнения\n",
    "исследования:\n",
    "15.07.2024 12:32\n",
    "Исследование выполнено на автоматическом биохимическом анализаторе AU480 (Beckman Coulter, США)\n",
    "№\n",
    "Исследование\n",
    "Результат\n",
    "Ед. изм.\n",
    "Интерпретация\n",
    "БИОХИМИЧЕСКИЕ ИССЛЕДОВАНИЯ КРОВИ\n",
    "134\n",
    "ммоль/л\n",
    "4.76\n",
    "Глюкоза\n",
    "4,39\n",
    "5,93\n",
    "156\n",
    "мкмоль/л\n",
    "23.1\n",
    "Железо\n",
    "12,5\n",
    "32,2\n",
    "160\n",
    "нг/мл\n",
    "115.0\n",
    "Ферритин\n",
    "20,0\n",
    "250,0\n",
    "Результат лабораторного исследования не является диагнозом. Согласно федеральному закону №323-ФЗ от 21.11.2011 (ред. от\n",
    "29.07.2017) «Об основах охраны здоровья граждан в Российской Федерации» диагноз устанавливает лечащий врач, основываясь\n",
    "на всестороннем обследовании пациента: сбор и анализ жалоб, данные анамнеза и осмотра, проведение лабораторных,\n",
    "инструментальных и иных исследований.\n",
    "Выполнил:\n",
    "Биолог КДЛ Елисеева Л. В.\n",
    "1 из 1\n",
    " B = H Ht) Tt. 8-928-111-22-11\n",
    "_] e-mail: official@ avenumed.ru\n",
    "eb NABOPATOPIA WwWw.avenumed.ru\n",
    "\n",
    "000 “CeBepnan 3Be3ga” WHH 6141045157 OFPH 1136181005135 Siny. J1041-01050-61/00327726\"\"\"\n",
    "\n",
    "extracted_data = extract_json_from_text(input_text)\n",
    "print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "     ---------------------------------------- 9.5/9.5 MB 340.5 kB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp310-cp310-win_amd64.whl (199.4 MB)\n",
      "     ------------------------------------ 199.4/199.4 MB 294.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "     ------------------------------------ 285.9/285.9 kB 629.3 kB/s eta 0:00:00\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-2.1.1-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     -------------------------------------- 12.9/12.9 MB 486.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (3.16.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.7.24-cp310-cp310-win_amd64.whl (269 kB)\n",
      "     ------------------------------------ 269.7/269.7 kB 395.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 612.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 462.8 kB/s eta 0:00:00\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 6.2/6.2 MB 496.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, numpy, networkx, MarkupSafe, jinja2, torch, tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\User\\\\Desktop\\\\Projects\\\\medical_chat_bot\\\\project_venv\\\\Lib\\\\site-packages\\\\~okenizers\\\\tokenizers.cp310-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "     ------------------------------------ 139.8/139.8 kB 129.5 kB/s eta 0:00:00\n",
      "Collecting widgetsnbextension~=4.0.12\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 20.0 kB/s eta 0:00:00\n",
      "Collecting jupyterlab-widgets~=3.0.12\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "     ------------------------------------- 214.4/214.4 kB 13.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipywidgets) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\desktop\\projects\\medical_chat_bot\\project_venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8b9180832e47028c7689e470326acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|          | 0/2 [1:02:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the appropriate model name or path\u001b[39;00m\n\u001b[0;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define the prompt template for extracting structured data as JSON\u001b[39;00m\n\u001b[0;32m     12\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124mYou are an AI assistant capable of extracting structured information from medical documents. Given a passage, extract specific information and return it only as a JSON object. The JSON should include the following fields depending on the type of document:\u001b[39m\n\u001b[0;32m     14\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124mNow, process the following text: \u001b[39m\u001b[38;5;132;01m{input_text}\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\transformers\\modeling_utils.py:3715\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[0;32m   3713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m   3714\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[1;32m-> 3715\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3724\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3726\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3727\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3731\u001b[0m     is_safetensors_available()\n\u001b[0;32m   3732\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   3733\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3734\u001b[0m ):\n\u001b[0;32m   3735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\transformers\\utils\\hub.py:1079\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[1;32m-> 1079\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\transformers\\utils\\hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    551\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\urllib3\\response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\urllib3\\response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\urllib3\\response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\urllib3\\response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the LLaMA model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Replace with the appropriate model name or path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the prompt template for extracting structured data as JSON\n",
    "prompt_template = \"\"\"\n",
    "You are an AI assistant capable of extracting structured information from medical documents. Given a passage, extract specific information and return it only as a JSON object. The JSON should include the following fields depending on the type of document:\n",
    "\n",
    "Medical Tests (анализы):\n",
    "Test Name \n",
    "Reference Range (e.g., norms for the test)\n",
    "Units (e.g., г/дл, %)\n",
    "Test Results (e.g., numerical values or text)\n",
    "Test Date\n",
    "Test Location (e.g., the name of the medical institution)\n",
    "Test Address\n",
    "Medical Studies (исследования):\n",
    "Study Name (e.g., \"Ультразвуковое исследование\")\n",
    "Study Date\n",
    "Study Location (e.g., the name of the medical institution)\n",
    "Device (e.g., the equipment used for the study)\n",
    "Study Protocol\n",
    "Study Conclusion\n",
    "Study Recommendations\n",
    "Study Address\n",
    "If certain information is not present in the text, return those fields as 'null'. The extracted data should be structured and presented as a json file to the user.\n",
    "\n",
    "Now, process the following text: {input_text}\n",
    "\"\"\"\n",
    "\n",
    "def extract_json_from_text(input_text):\n",
    "    # Format the prompt with the input text\n",
    "    prompt = prompt_template.format(input_text=input_text)\n",
    "    \n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    \n",
    "    # Generate the completion using LLaMA\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=1500,  # Adjust length based on expected output size\n",
    "            num_beams=5,      # Adjust number of beams for beam search\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract and return the JSON part from the response\n",
    "    json_match = re.search(r'\\{[\\w\\W]*\\}', generated_text)\n",
    "    if json_match:\n",
    "        return json.loads(json_match.group())\n",
    "    else:\n",
    "        return {\"error\": \"No valid JSON found in the response\"}\n",
    "\n",
    "# Example usage\n",
    "input_text = \"\"\"\n",
    "РЕЗУЛЬТАТЫ ЛАБОРАТОРНЫХ ИССЛЕДОВАНИЙ\n",
    "ФИО пациента:\n",
    "Шахмурадян Михаил Андреевич\n",
    "Вид биоматериала: Венозная кровь\n",
    "Тип пробы:\n",
    "Дата рождения:\n",
    "07.10.1993\n",
    "Плазма крови\n",
    "Дата поступления\n",
    "биоматериала:\n",
    "14.07.2024 14:26\n",
    "Мужской\n",
    "Пол:\n",
    "Дата выполнения\n",
    "исследования:\n",
    "15.07.2024 12:32\n",
    "Исследование выполнено на автоматическом биохимическом анализаторе AU480 (Beckman Coulter, США)\n",
    "№\n",
    "Исследование\n",
    "Результат\n",
    "Ед. изм.\n",
    "Интерпретация\n",
    "БИОХИМИЧЕСКИЕ ИССЛЕДОВАНИЯ КРОВИ\n",
    "134\n",
    "ммоль/л\n",
    "4.76\n",
    "Глюкоза\n",
    "4,39\n",
    "5,93\n",
    "156\n",
    "мкмоль/л\n",
    "23.1\n",
    "Железо\n",
    "12,5\n",
    "32,2\n",
    "160\n",
    "нг/мл\n",
    "115.0\n",
    "Ферритин\n",
    "20,0\n",
    "250,0\n",
    "Результат лабораторного исследования не является диагнозом. Согласно федеральному закону №323-ФЗ от 21.11.2011 (ред. от\n",
    "29.07.2017) «Об основах охраны здоровья граждан в Российской Федерации» диагноз устанавливает лечащий врач, основываясь\n",
    "на всестороннем обследовании пациента: сбор и анализ жалоб, данные анамнеза и осмотра, проведение лабораторных,\n",
    "инструментальных и иных исследований.\n",
    "Выполнил:\n",
    "Биолог КДЛ Елисеева Л. В.\n",
    "1 из 1\n",
    " B = H Ht) Tt. 8-928-111-22-11\n",
    "_] e-mail: official@ avenumed.ru\n",
    "eb NABOPATOPIA WwWw.avenumed.ru\n",
    "\n",
    "000 “CeBepnan 3Be3ga” WHH 6141045157 OFPH 1136181005135 Siny. J1041-01050-61/00327726\"\"\"\n",
    "\n",
    "extracted_data = extract_json_from_text(input_text)\n",
    "print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 10, 10, 0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "# Example date-like string\n",
    "date_str1 = \"10 Oct 2024\"\n",
    "date_str2 = \"15.07.2024\"\n",
    "\n",
    "# Automatically parse different formats\n",
    "date_obj1 = parser.parse(date_str1)\n",
    "date_obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "syntax error at or near \"IF\"\nLINE 1: CREATE DATABASE \"medicaldb\" IF NOT EXISTS\n                                    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m cur \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Use the psycopg2.sql module instead of string concatenation \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# in order to avoid sql injection attacks.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSQL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE DATABASE \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m IF NOT EXISTS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIdentifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedicaldb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSyntaxError\u001b[0m: syntax error at or near \"IF\"\nLINE 1: CREATE DATABASE \"medicaldb\" IF NOT EXISTS\n                                    ^\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT # <-- ADD THIS LINE\n",
    "\n",
    "con = psycopg2.connect(dbname='araks',\n",
    "      user='postgres', host='localhost',\n",
    "      password='Tiko.777', port=5433)\n",
    "\n",
    "con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT) # <-- ADD THIS LINE\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "# Use the psycopg2.sql module instead of string concatenation \n",
    "# in order to avoid sql injection attacks.\n",
    "cur.execute(sql.SQL(\"CREATE DATABASE {} IF NOT EXIST\").format(\n",
    "        sql.Identifier('medicaldb'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Smith - jane.smith@example.com (Created: 2024-09-09 19:35:06.194806)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12236\\3649418658.py:7: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the SQLAlchemy base class\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define a model for the table\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    first_name = Column(String, nullable=False)\n",
    "    last_name = Column(String, nullable=False)\n",
    "    email = Column(String, unique=True, nullable=False)\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "\n",
    "# Create an engine and a session\n",
    "DATABASE_URL = 'postgresql://postgres:Tiko.777@localhost:5433/postgres'\n",
    "engine = create_engine(DATABASE_URL)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Create the tables in the database\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Insert new data into the table\n",
    "new_user = User(first_name='Jane', last_name='Smith', email='jane.smith@example.com')\n",
    "session.add(new_user)\n",
    "session.commit()\n",
    "\n",
    "# Query the database\n",
    "users = session.query(User).all()\n",
    "for user in users:\n",
    "    print(f'{user.first_name} {user.last_name} - {user.email} (Created: {user.created_at})')\n",
    "\n",
    "# Close the session\n",
    "session.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected bytes or unicode string, got ellipsis instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m con \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m cursor \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedicalTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      8\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     ]\n\u001b[0;32m     45\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\psycopg2\\__init__.py:121\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Projects\\medical_chat_bot\\project_venv\\lib\\site-packages\\psycopg2\\extensions.py:145\u001b[0m, in \u001b[0;36mmake_dsn\u001b[1;34m(dsn, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# If no kwarg is specified don't mung the dsn, but verify it\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[1;32m--> 145\u001b[0m     \u001b[43mparse_dsn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dsn\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Override the dsn with the parameters\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected bytes or unicode string, got ellipsis instead"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg.connect(dbname=\"MY_DATABASE\", user=\"MY_USERNAME\", password=\"MY_PASSPHRASE\", host=\"IP_ADDRESS\", port=\"PORT\" ) \n",
    "cursor = conn.cursor()\n",
    "\n",
    "data = {\n",
    "    \"MedicalTest\": [\n",
    "        {\n",
    "            \"TestName\": \"Глюкоза\",\n",
    "            \"ReferenceRange\": [\n",
    "                4.39,\n",
    "                5.93\n",
    "            ],\n",
    "            \"Units\": \"ммоль/л\",\n",
    "            \"TestResults\": \"4.76\",\n",
    "            \"TestDate\": \"15.07.2024\",\n",
    "            \"TestLocation\": None,\n",
    "            \"TestAddress\": None\n",
    "        },\n",
    "        {\n",
    "            \"TestName\": \"Железо\",\n",
    "            \"ReferenceRange\": [\n",
    "                12.5,\n",
    "                32.2\n",
    "            ],\n",
    "            \"Units\": \"мкмоль/л\",\n",
    "            \"TestResults\": \"23.1\",\n",
    "            \"TestDate\": \"15.07.2024\",\n",
    "            \"TestLocation\": None,\n",
    "            \"TestAddress\": None\n",
    "        },\n",
    "        {\n",
    "            \"TestName\": \"Ферритин\",\n",
    "            \"ReferenceRange\": [\n",
    "                20.0,\n",
    "                250.0\n",
    "            ],\n",
    "            \"Units\": \"нг/мл\",\n",
    "            \"TestResults\": \"115.0\",\n",
    "            \"TestDate\": \"15.07.2024\",\n",
    "            \"TestLocation\": None,\n",
    "            \"TestAddress\": None\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "query_sql = \"\"\"\n",
    "insert into table1 select * from\n",
    "json_populate_record(NULL::table1, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_sql, (data,))\n",
    "conn.commit()\n",
    "cursor.execute('select * from table1')\n",
    "print(cursor.fetchall())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
